# p, q, spread: p-q = p - (1-p) = 2p -1
# to predict the parameter p using the observed data in the sample
# estimate: summary of the observed data that we think is informative about the parameter of interest

# Standard error = (1-0)*sqrt(pq) => SE(S) = sqrt(npq), n = sample size
# SE(Xbar) = sqrt(pq/N)
# E(X bar) = p

# Pr(|Xbar - p| <= 0.01) = Pr(Xbar <= p+0.01) - Pr(Xbar <= p-0.01)
#   => Pr(Z <= 0.01/sqrt(p(1-p)/N)) - Pr(Z <= -0.01/sqrt(p(1-p)/N))
#   => pnorm(0.01/se) - pnorm(-0.01/se)
# plug-in estimate: SE(Xbar) = sqrt(p(1-p)/N) => SE^(Xbar) = sqrt(Xbar(1-Xbar)/N) (SE hat: estimate value)
> x_hat = 0.48
> se = sqrt(x_hat*(1-x_hat)/25)
> se
[1] 0.09991997
> pnorm(0.01/se) - pnorm(-.01/se)
[1] 0.07971926

# margin of error: 2 times of S.E.
# Pr(|Xbar - p| <= 2SE(Xbar)) => Pr(Z <= 2) - Pr(Z<= -2)

# Monte Carlo Simulation for the CLT
> B = 10000
> N = 1000
> X_hat = replicate(B, {
    + X = sample(c(0,1), N, replace= TRUE, prob= c(1-p,p))
    + mean(X)
    + })
# this code cannot run because we don't know p! Though, we can pick a p for testing.
take_poll(n=1000)

> p = 0.45
> N = 1000
> X = sample(c(0,1), N, replace = T, prob=c(1-p,p))
> X_hat = mean(X)
# take into MCS for 10,000 times
B = 10000
X_hat = replicate(B, {
    +   X = sample(c(0,1), N, replace = T, prob=c(1-p,p))
    +   mean(X)
    + })
> mean(X_hat)
[1] 0.4500811
> sd(X_hat)
[1] 0.01571974

> p1 = data.frame(X_hat=X_hat) %>% ggplot(aes(X_hat)) +
    + geom_histogram(binwidth = 0.005, color = "black")

> p2 = data.frame(X_hat=X_hat) %>% ggplot(aes(sample = X_hat)) +
    + stat_qq(dparams = list(mean=mean(X_hat), sd = sd(X_hat))) +
    + geom_abline() +
    + ylab("X_hat")+
    + xlab("Theoretical normal")

# confidence intervals
geom_smooth()

> p = 0.45
> N = 1000
> X = sample(c(0,1), N, replace = T, prob = c(1-p,p))
> X_hat = mean(X)
> SE_hat = sqrt(X_hat*(1-X_hat)/N)
> c(X_hat - 2*SE_hat, X_hat + 2*SE_hat)
[1] 0.4274837 0.4905163  # this C.I. is not fixed because generated by random variable (X_hat).

# Pr(Xbar - 2*SE_hat(Xbar) <= p <= Xbar + 2*SE_hat(Xbar))
# => Pr(-2 <= (Xbar - p)/SE_hat(Xbar) <= 2)
# => Pr(-2 <= Z <= 2)  ~ 95% C.I.
z = qnorm(0.995)
z
[1] 2.575829
pnorm(qnorm(0.995))
[1] 0.995
pnorm(z)-pnorm(-z)
[1] 0.99
qnorm(0.975)
[1] 1.96

# MCS for CI
> B = 10000
> inside = replicate(B, {
    + X = sample(c(0,1), N, replace = T, prob = c(1-p,p))
    + X_hat = mean(X)
    + SE_hat = sqrt(X_hat*(1-X_hat)/N)
    + between(p, X_hat - 2* SE_hat, X_hat + 2* SE_hat) # return T or F
    + })
> mean(inside)
[1] 0.9514

# Pr(sqrt(N) * |Xbar - 0.5|/sqrt(0.5*(1-0.5)) > sqrt(N) * 0.02/sqrt(0.5(1-0.5))
# Pr(sqrt(N) * |Xbar - 0.5|/0.5 > Z)

# Calculate the standard error of the spread and save it to a variable called `se_hat`. Print this value to the console.
se_hat =2*sqrt(X_hat*(1-X_hat)/N)  # times 2 because of spread ???

# poll aggregators
> d = 0.039
> Ns = c(1298,533,1342,897,774,254,812,324,1291,1056,2172,516)
> p = (d+1)/2
>
    > confidence_intervals = sapply(Ns, function(N) {
        + x = sample(c(0,1), N, replace = T, prob = c(1-p,p))
        + X_hat = mean(X)
        + SE_hat = sqrt(X_hat*(1-X_hat)/N)
        + 2*c(X_hat, X_hat - 2*SE_hat, X_hat + 2*SE_hat)-1
    })
> polls = data.frame(poll=1:ncol(confidence_intervals),
                     + t(confidence_intervals),
                     + sample_size = Ns)
> names(polls) = c("poll","estimate","low","hight","sample_size")
> polls
poll  estimate        low      hight sample_size
1     1 -0.895308 -0.9200360 -0.8705800        1298
2     2 -0.895308 -0.9338970 -0.8567190         533
3     3 -0.895308 -0.9196273 -0.8709887        1342
4     4 -0.895308 -0.9250541 -0.8655619         897
5     5 -0.895308 -0.9273306 -0.8632854         774
6     6 -0.895308 -0.9512077 -0.8394083         254
7     7 -0.895308 -0.9265723 -0.8640437         812
8     8 -0.895308 -0.9448022 -0.8458138         324
9     9 -0.895308 -0.9201030 -0.8705130        1291
10   10 -0.895308 -0.9227234 -0.8678926        1056
11   11 -0.895308 -0.9144240 -0.8761920        2172
12   12 -0.895308 -0.9345275 -0.8560885         516

sum(polls$sampel_size)
[1] 11269
d_hat = polls %>% + summarize(avg = sum(estimate*sample_size)/sum(sample_size)) %>% + .$avg
p_hat = (1+d)/2
moe = 2*1.96*sqrt(p_hat*(1-p_hat)/sum(polls$sample_size))
moe
[1] 0.0185
round(d_hat*100,1) # spread: 3.1% +- 1.8%
[1] 3.1
round(moe*100,1)
[1] 1.8

##
polls = polls_us_election_2016 %>%
    + filter(state == "U.S." & enddate >= "2016-10-31" & (grad %in% c("A+","A","A-","B+") | is.na(grade)))
polls = polls %>% mutate(spread = rawpoll_clinton/100 - rawpoll_trump/100)
# expected value: d = 2p-1
# standard error: 2sqrt(p(1-p)/N)
d_hat = polls %>% summarize(d_hat = sum(spread * samplesize)/sum(samplesize)) %>% .$d_hat
p_hat = (d_hat+1)/2
moe = 1.96*2*sqrt(p_hat*(1-p_hat)/sum(polls$samplesize))
polls $>$ ggplota(aes(spread)) + geom_histogram(color="black", binwidth = .01)
# show polls number
polls %>% group_by(pollster) %>%
    +   filter( n() >= 6) %>% ggplot(aes(pollster,spread)) + geom_point() + theme(axis.text.x = element_text(angle =90, hjust =1))
# house effect or poll bias

# data-driven models
one_poll_per_pollster = polls %>% group_by(pollster) %>% filter(enddate == max(enddate)) %>% ungroup()
one_poll_per_pollster %>% ggplot(aes(spread)) + geom_histogram(binwidth = 0.01)
# standard error now includes pollster to pollster variabiliy. sigma ~ sd
sd(one_poll_per_pollster$spread)
results = one_poll_per_pollster %>% summarize(avg = mean(spread), se = sd(spread)/sqrt(length(spread))) %>%
    + mutate(start = avg - 1.96*se, end = avg + 1.96*se)
round(results*100,1)
avg  se  start end
1   2.9 0.6    1.7 4.1

#Bayes' Theorem
prevalence = 0.00025
N = 100000
outcome = sample(c("Disease","Healthy"), N, replace = TRUE, prob = c(prevalnce, 1 - prevalence))
N_D = sum(outcome =="Disease")
N_H = sum(outcome =="Healthy")
accuracy = 0.99
test = vector("character",N)
test[outcome == "Disease"] = sample(c("+","-"), N_D, replace = T, prob = c(accuracy, 1- accuracy))
test[outcome == "Healthy"] = sample(c("-","+"), N_H, replace = T, prob = c(accuracy, 1- accuracy))
table(outcome, test)
test
outcome       -    +
    Disease     0   23
Healthy 99012  965
# p ~ N(mu, tau) describes randomness in picking a player.  mu is 0.27, tau = 0.027
#   p is a random variable, has a distribution that is normal, with an expected value mu, and standard error tau
# Y | p ~ N(p, sigma) describes randomness in the performace of this particular player. sigma^2 = p(1-p)/N
# 2 levels -> hierarchical model: 1st level is prior distribution, 2nd level is sampling distribution

# p ~ N(0.275, 0.027)
# Y | p ~ N(p, 0.111)
# -> posterior distribution/posterior probability distribution
# E(p|y) = Bmu + (1-B)Y = mu + (1-B)(Y-mu);     B = sigma^2/(sigma^2 + tau^2) => B is closer to 1 when sigma is large
# shrink the observed data towards what the average player is, mu.

# E(p|Y=0.45) = B*0.275 + (1-B)*0.450 = 0.275 + (1-B)(0.450 - 0.275)
# B = .111^2/(.111^2 + .027^2) = 0.944
# E(p|Y=0.45) = .285
# SE(p|y)^2 = 1/(1/sigma^2 + 1/tau^2) = 1/(1/.111^2 + 1/.027^2) = 0.00069
# credible interval: E(p|Y) +- 2*SE(p|y)
# frequentist confidence interval

# t distribution:
z = qt(0.975, nrow(one_poll_per_pollster)-1)  # degree of freedom
one_poll_per_pollster %>% summarize(avg = mean(spread), moe = z*sd(spread)/sqrt(length(spread))) %>%
    +   mutate(start = avg - moe, end = avg + moe)

qt(0.975, 14) # quantile of t distribution
[1] 2.144787
qnorm(0.975)  # quantile of normal distribution
[1] 1.959964